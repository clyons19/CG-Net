{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb08c7d",
   "metadata": {},
   "source": [
    "CG-Net.ipynb \n",
    "* Created by: Carter Lyons\n",
    "\n",
    "Contains:\n",
    "* Deep neural network implementation of Compound Gaussian Network (CG-Net) form by applying algorithm unrolling to the Compound Gaussian Least Squares (CG-LS) iterative algorithm. Estimates signal representation coefficients from linear measurements.\n",
    "* For more information reference:\n",
    "    1. Lyons, C., Raj, R. G., & Cheney, M. (2023). \"A Compound Gaussian Network for Solving Linear Inverse Problems\". arXiv preprint arXiv:2305.11120.\n",
    "    2. Lyons C., Raj R. G., and Cheney M. (2022). \"CG-Net: A Compound Gaussian Prior Based Unrolled Imaging Network,\" in *2022 IEEE Asia-Pacific Signal and Information Processing Association Annual Summit and Conference*, pp. 623-629.\n",
    "\n",
    "Package Requirements (in addition to those required in Initialize.py):\n",
    "* Tensorflow 2.5.0, pandas, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14ca26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary python packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import necessary additional code files\n",
    "import Initialize\n",
    "import LossFunctions\n",
    "from CGNet import CGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48a741",
   "metadata": {},
   "source": [
    "# Create Network Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b970729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose network parameters\n",
    "img_size = 32  # Height and width of input images \n",
    "style = 'tridiag'  # Format of PD matrix in z quadratic descent direction. Options: 'tridiag', 'full'\n",
    "angles = 15  # Number of uniformly spaced angles for Radon transform\n",
    "noise = 60  # SNR of measurements (in dB)\n",
    "K = 20  # Number of iterations to unroll\n",
    "J = 1  # Number of steepest descent updates of z for each interation to unroll\n",
    "scale = 1  # Parameter to scale the input measurements by\n",
    "path_to_save = r'path_to_desired_save_folder'  # Path to save weights trained by the network.\n",
    "\n",
    "n = img_size**2  # Signal size\n",
    "B = Initialize.create_measurements('barbara.png', [[154, 154+img_size],[64,64+img_size]], import_phi = (False, [], 'bior1.1'), import_psi = (False, [], angles))  # From Initialize.py: Create Radon transform matrix. Create biorthogonal wavelet matrix. Use these matrices to form measurements of input 'Barbara' image\n",
    "A = tf.constant(B.Psi@B.Phi, dtype = float)  # Measurement matrix: A = Psi*Phi (set dtype to float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a4db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network structure\n",
    "model = CGNet(K, J, A, style, 0.1, kappa = 2, eta = 0.5, eps = 1e-3, method = 'g', normalize = True)\n",
    "model = model.call()\n",
    "loss_fnc = LossFunctions.SSIM_loss(B.Phi, img_size, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc09f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = 20\n",
    "model.load_weights(r'Weights\\CGNet_{}angles_{}dB_{}_samples.h5'.format(angles, noise, num_training_samples))  # Load network variables (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01764187",
   "metadata": {},
   "source": [
    "# Read in Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc73a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test_data = r'Datasets\\200_32x32_{}angles_{}dB_test_data.csv'.format(angles, noise)  # Path to testing dataset\n",
    "test_data = pd.read_csv(path_to_test_data)  # Read in testing dataset\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)  # Drops first column of dataset, which is a numbering of the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7759ad",
   "metadata": {},
   "source": [
    "# Average Quality Metrics on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Validate\n",
    "V = Validate.AverageMetrics(B.Phi, img_size, scale, power = 1, normalize = True)  # From Validate.py: Used to calculate SSIM, PSNR, MSE, and MAE between estiamted and actual signals\n",
    "\n",
    "test_data_size = len(test_data)\n",
    "num_batches = int(np.ceil(test_data_size/TestBatchSize))\n",
    "run_time = []\n",
    "for batch in range(num_batches):\n",
    "    y = scale*np.array(test_data.iloc[batch*TestBatchSize:min([(batch+1)*TestBatchSize,test_data_size])])\n",
    "    c_act, y = y[:,np.shape(B.Psi)[0]:], y[:,:np.shape(B.Psi)[0]]\n",
    "    start = time.time()\n",
    "    c_est = model(y, training = False)\n",
    "    run_time.append((time.time()-start)/np.shape(y)[0])\n",
    "    V.call(c_act, c_est)  # Calculate SSIM, PSNR, MSE, and MAE between estiamted and actual signal\n",
    "\n",
    "V.data['TIME'] = run_time    \n",
    "data = []\n",
    "for entry in V.data:\n",
    "    data.append([entry, np.mean(V.data[entry]), np.var(V.data[entry]), 2.576*np.sqrt(np.var(V.data[entry])/test_data_size)])  # Calculates average over all test data, variance over all test data, and 99% confidence interval\n",
    "    print(entry+' AVE = {:0.3e} '.format(np.mean(V.data[entry]))+entry+' VAR = {:0.3e}'.format(np.var(V.data[entry])))\n",
    "r = pd.DataFrame(data)\n",
    "r.to_csv(r'{}_TestResults.csv'.format(path_to_save))  # Save test results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f03f0",
   "metadata": {},
   "source": [
    "# Visual Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb9c1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.transpose(B.add_noise(noise, B.y))\n",
    "est = model(y, training=False)\n",
    "c_est = np.array(tf.transpose(est))\n",
    "I_est = B.Phi@c_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_act = B.I\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.reshape(I_est, (img_size, img_size)), cmap = 'gray')  # Display estimated image\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.reshape(I_act, (img_size, img_size)), cmap = 'gray')  # Display actual image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362df332",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "num_images = 10\n",
    "y = scale*np.array(test_data.iloc[start:start+num_images])\n",
    "c_act = y[:,np.shape(B.Psi)[0]:]\n",
    "y = y[:,:np.shape(B.Psi)[0]]\n",
    "est = model(y, training=False)\n",
    "c_est = np.array(tf.transpose(est))\n",
    "I_est = np.array(B.Phi@c_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a26e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9  # Anything between 'start' and 'start+num_images-1'\n",
    "I_act = B.Phi@np.transpose(c_act[i])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.reshape(I_est[:,i], (img_size, img_size)), cmap = 'gray')  # Display estimated image\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.reshape(I_act, (img_size, img_size)), cmap = 'gray')  # Display actual image\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldtf",
   "language": "python",
   "name": "oldtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
